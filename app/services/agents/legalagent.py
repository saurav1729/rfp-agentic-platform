# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pq54WVj3nBBClgf-iUIkFkpyltD9Xud7
"""

!pip install -q google-generativeai PyPDF2 pdf2image pytesseract pillow numpy tqdm
!apt-get -y install tesseract-ocr >/dev/null 2>&1
print("Install step complete.")

from google.colab import userdata
import google.generativeai as genai

API_KEY = userdata.get("gemini_key")
if not API_KEY:
    raise RuntimeError("Gemini API key not found. Save it as a Colab Secret named 'gemini_key'")

genai.configure(api_key=API_KEY)
print("Gemini configured.")

import os, json, re, uuid
import numpy as np
from tqdm import tqdm
from time import sleep
import PyPDF2
from pdf2image import convert_from_path
import pytesseract
from google.colab import files

def safe_truncate(s, n=800):
    return s if len(s) <= n else s[:n] + "..."

print("Utilities loaded.")

class LegalAgent:
    def __init__(self, genai_module=None):
        # Accept an injected genai module (default to configured google.generativeai)
        self.genai = genai if genai_module is None else genai_module
        # No print here to avoid duplicate messages (Gemini already configured earlier)

    # ----------------------------------------
    # PDF -> text (PyPDF2 + OCR fallback)
    # ----------------------------------------
    def extract_text_from_pdf(self, path):
        text = ""
        # Try text extraction
        try:
            reader = PyPDF2.PdfReader(path)
            for p in reader.pages:
                t = p.extract_text()
                if t:
                    text += t + "\n"
        except Exception as e:
            print("PyPDF2 read error (will try OCR):", e)

        # If extracted text is too short, fallback to OCR
        if len(text.strip()) < 50:
            try:
                imgs = convert_from_path(path, dpi=200)
                for img in imgs:
                    text += pytesseract.image_to_string(img) + "\n"
            except Exception as e:
                print("OCR fallback failed:", e)

        return text

    # ----------------------------------------
    # Chunking + cosine sim
    # ----------------------------------------
    def create_chunks(self, text, chunk_words=400, overlap_words=50):
        words = text.split()
        chunks = []
        i = 0
        while i < len(words):
            chunk = words[i:i+chunk_words]
            chunks.append(" ".join(chunk))
            i += (chunk_words - overlap_words)
        return chunks

    def cosine_sim(self, a, b):
        a = np.array(a, dtype=np.float32)
        b = np.array(b, dtype=np.float32)
        if np.linalg.norm(a)==0 or np.linalg.norm(b)==0:
            return 0.0
        return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))

    # ----------------------------------------
    # Embedding wrapper using Gemini embeddings model
    # ----------------------------------------
    def get_embedding(self, text, model_name="models/text-embedding-004", retries=3):
        for attempt in range(retries):
            try:
                emb_response = genai.embed_content(model=model_name, content=text)
                return emb_response['embedding']
            except Exception as e:
                print(f"Embedding attempt {attempt+1} error: {e}")
                sleep(1 + attempt*2)
        raise RuntimeError("Failed to get embedding after retries")

    # ----------------------------------------
    # Summarize and evaluate helper functions (uses Gemini text gen)
    # ----------------------------------------
    def genai_summarize(self, text, instruction="Summarize the following text in a concise, structured bullet list. Include main obligations, deadlines, acceptance criteria, and risks."):
        prompt = f"{instruction}\n\nText:\n{text}\n\nProvide a concise structured summary."
        model = genai.GenerativeModel("models/gemini-2.5-flash")
        resp = model.generate_content(prompt)
        return resp.text.strip()

    def genai_evaluate_compliance(self, rfp_snippets, proposal_snippet, question_context=None):
        if question_context is None:
            question_context = ("Is the proposal excerpt compliant with the RFP requirements? "
                                "Answer with: Verdict (Compliant / Non-compliant). Then a 2-3 sentence justification. "
                                "If Non-compliant, bullet list missing / conflicting items from the RFP.")
        rfp_text = "\n\n---\n\n".join(rfp_snippets)
        prompt = f"""
You are a contract-review assistant.

RFP relevant excerpts:
{rfp_text}

Proposal excerpt:
{proposal_snippet}

Task:
{question_context}

Answer format (strict):
1) Verdict: Compliant / Non-compliant
2) Short justification (2-3 sentences)
3) If Non-compliant: bullet list of missing/contradicting RFP items
"""
        model = genai.GenerativeModel("models/gemini-2.5-flash")
        resp = model.generate_content(prompt)
        return resp.text.strip()

    # ----------------------------------------
    # Semantic search (top-k by cosine similarity)
    # ----------------------------------------
    def semantic_search(self, query_emb, corpus_embeddings, top_k=5):
        scores = [(i, self.cosine_sim(query_emb, emb)) for i, emb in enumerate(corpus_embeddings)]
        scores.sort(key=lambda x: x[1], reverse=True)
        return scores[:top_k]

    # ----------------------------------------
    # Main pipeline: process two PDFs and produce report
    # ----------------------------------------
    def run(self, rfp_pdf_path, proposal_pdf_path, chunk_words=400, top_k=5, similarity_threshold=0.55):
        print("Extracting RFP text...")
        rfp_text = self.extract_text_from_pdf(rfp_pdf_path)
        print("Extracting Proposal text...")
        proposal_text = self.extract_text_from_pdf(proposal_pdf_path)

        if len(rfp_text.strip()) < 20:
            raise RuntimeError("RFP extraction seems empty.")
        if len(proposal_text.strip()) < 20:
            raise RuntimeError("Proposal extraction seems empty.")

        print("Creating chunks...")
        rfp_chunks = self.create_chunks(rfp_text, chunk_words=chunk_words)
        proposal_chunks = self.create_chunks(proposal_text, chunk_words=chunk_words)

        print(f"RFP -> {len(rfp_chunks)} chunks, Proposal -> {len(proposal_chunks)} chunks")

        print("Embedding RFP chunks...")
        rfp_embeddings = [self.get_embedding(c) for c in tqdm(rfp_chunks)]

        print("Embedding Proposal chunks...")
        proposal_embeddings = [self.get_embedding(c) for c in tqdm(proposal_chunks)]

        # Summarize RFP (use a sample / top chunks to stay within prompt limits)
        print("Summarizing RFP (high-level)...")
        sample_for_summary = " ".join(rfp_chunks[:6]) if len(rfp_chunks) > 0 else rfp_text
        rfp_summary = self.genai_summarize(sample_for_summary,
                                      instruction="You are a contract analyst. Produce a clear summary of key requirements, deliverables, deadlines, acceptance criteria, and penalties.")

        print("\nRFP summary generated.")

        # Evaluate proposal chunks
        print("Evaluating proposal for compliance...")
        findings = []
        for idx, (p_chunk, p_emb) in enumerate(tqdm(list(zip(proposal_chunks, proposal_embeddings)), total=len(proposal_chunks))):
            top = self.semantic_search(p_emb, rfp_embeddings, top_k=top_k)
            top_indices = [i for i, s in top]
            top_scores = [s for i, s in top]
            if len(top_scores) == 0 or top_scores[0] < similarity_threshold:
                continue  # skip weak matches
            top_snippets = [rfp_chunks[i] for i in top_indices]
            evaluation = self.genai_evaluate_compliance(top_snippets, p_chunk)
            findings.append({
                "proposal_chunk_index": idx,
                "proposal_excerpt": safe_truncate(p_chunk, 800),
                "top_rfp_matches_indices": top_indices,
                "top_scores": top_scores,
                "evaluation": evaluation
            })

        # Aggregate simple verdict
        compliant_count = sum(1 for f in findings if "non-compliant" not in f["evaluation"].lower() and "compliant" in f["evaluation"].lower())
        non_compliant_count = sum(1 for f in findings if "non-compliant" in f["evaluation"].lower())
        total_checks = compliant_count + non_compliant_count
        if total_checks == 0:
            overall = "No strong matches found â€” cannot determine compliance automatically."
        else:
            pct_compliant = 100 * compliant_count / total_checks
            overall = f"{pct_compliant:.1f}% of matched proposal segments appear compliant ({compliant_count}/{total_checks}). {non_compliant_count} matched segments flagged non-compliant."

        report = {
            "rfp_summary": rfp_summary,
            "overall_verdict": overall,
            "detailed_findings": findings,
            "metadata": {
                "rfp_chunks": len(rfp_chunks),
                "proposal_chunks": len(proposal_chunks),
                "checks_run": total_checks
            }
        }
        return report

# Cell 5 - Upload RFP and Proposal PDFs (use dialog), run the agent,
# and keep the report as an in-memory JSON-like Python object (do NOT write a file).
# -------------------------
print("Upload the RFP PDF file (choose file dialog)...")
uploaded = files.upload()
if len(uploaded) == 0:
    raise RuntimeError("No file uploaded for RFP.")
rfp_file = list(uploaded.keys())[0]

print("Now upload the Proposal PDF file...")
uploaded2 = files.upload()
if len(uploaded2) == 0:
    raise RuntimeError("No file uploaded for Proposal.")
proposal_file = list(uploaded2.keys())[0]

print("Starting processing (this can take a while depending on doc size and API speed)...")
agent = LegalAgent()
report = agent.run(rfp_file, proposal_file, chunk_words=400, top_k=5, similarity_threshold=0.55)

# --- Keep report as an in-memory Python dict (JSON object)
report_obj = report  # this is already a Python dict; you can use it directly

# Print concise outputs (same as before)
print("\n=== RFP Summary ===\n")
print(report_obj.get("rfp_summary", "No summary produced."), "\n")
print("=== Overall Verdict ===\n")
print(report_obj.get("overall_verdict", "No verdict produced."), "\n")

# Optionally show metadata and number of detailed findings
meta = report_obj.get("metadata", {})
print("Metadata:", meta)
print("Number of detailed findings:", len(report_obj.get("detailed_findings", [])))

# The report_obj variable now holds the full JSON-like object in memory.
# You can inspect it, pass it to other functions, convert to JSON string, or save later if needed.
# Example: convert to JSON string (in-memory)
report_json_string = json.dumps(report_obj, indent=2, ensure_ascii=False)

# If you want to preview the first 1000 characters of the JSON string:
print("\nPreview of JSON object (first 1000 chars):\n")
print(report_json_string[:1000])

# -------------------------
# Cell 6 - Print detailed findings (first N)
# -------------------------
N = 8
for i, f in enumerate(report["detailed_findings"][:N]):
    print(f"\n--- Finding {i+1} ---")
    print("Proposal excerpt (truncated):", f["proposal_excerpt"])
    print("Top RFP match indices:", f["top_rfp_matches_indices"])
    print("Top similarity scores:", [round(s,3) for s in f["top_scores"]])
    print("Evaluation by Gemini:\n", f["evaluation"])
    print("-"*60)